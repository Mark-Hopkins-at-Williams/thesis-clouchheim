{'tgt_num': 1, 'train_scope': [0, 10], 'dev_scope': [11, 20], 'test_scope': [21, 30]}
{'tgt_num': 2, 'train_scope': [0, 10], 'dev_scope': [11, 20], 'test_scope': [21, 30]}
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training models/encrypted/TEST-v19
Augmenting vocabulary with the following tokens:
  por1_Latn
  por2_Latn
Validating on a sample...
dev loss: 10.533813095092773
Saving new best model!
step 500 (train): 5.453924757570029
Validating on a sample...
dev loss: 9.998228554725648

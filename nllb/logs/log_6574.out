language pairs in model: [('eng_Latn', 'por1_Latn')]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training models/encrypted/mono1-v0
Augmenting vocabulary with the following tokens:
  por1_Latn
Validating on a sample...
dev loss: 11.801297807693482
Saving new best model!
step 500 (train): 8.297567600250245
Validating on a sample...
dev loss: 6.34661298751831

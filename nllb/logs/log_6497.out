huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training models/encrypted/TEST-v20
Augmenting vocabulary with the following tokens:
  por2_Latn
  por1_Latn
Validating on a sample...
dev loss: 11.824069948196412
Saving new best model!
step 500 (train): 9.426627259254456
Validating on a sample...
dev loss: 7.586831192970276
Saving new best model!
step 1000 (train): 7.0803920888900755
Validating on a sample...
dev loss: 7.004257302284241
Saving new best model!
step 1500 (train): 6.502443173885346
Validating on a sample...
dev loss: 6.976966066360474

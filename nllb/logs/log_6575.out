language pairs in model: [('eng_Latn', 'por1_Latn')]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training models/encrypted/mono2-v0
Augmenting vocabulary with the following tokens:
  por1_Latn
Validating on a sample...
dev loss: 11.842418565750123
Saving new best model!
step 500 (train): 8.312331007957459
Validating on a sample...
dev loss: 6.4707200145721435
